{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73876c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0771a95",
   "metadata": {},
   "source": [
    "Load Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fb0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3-3B-Instruct\", load_in_8bit=True, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b30b0f",
   "metadata": {},
   "source": [
    "LoRA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aee01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e203202",
   "metadata": {},
   "source": [
    "Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(text, label=\"\"):\n",
    "    return f\"\"\"\n",
    "### Instruction:\n",
    "Classify the following text into: Neutral, Hate-Speech, or Sarcasm.\n",
    "\n",
    "### Input:\n",
    "{text}\n",
    "\n",
    "### Output:\n",
    "{label}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85012a",
   "metadata": {},
   "source": [
    "Training Arguments & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a5f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    output_dir=\"./results\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    max_seq_length=512,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e83c3",
   "metadata": {},
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d045b",
   "metadata": {},
   "source": [
    "Evaluation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    prompt = format_example(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=5)\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    for label in [\"Neutral\", \"Hate-Speech\", \"Sarcasm\"]:\n",
    "        if label.lower() in decoded.lower():\n",
    "            return label\n",
    "    return \"Neutral\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
